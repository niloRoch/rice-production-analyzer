# ===============================================================================
# AN√ÅLISE COMPLETA: PREDI√á√ÉO DE PRODU√á√ÉO DE ARROZ
# Autor: Seu Nome
# Data: Agosto 2025
# ===============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# Machine Learning
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.inspection import permutation_importance

# Interpretabilidade
import shap

# XGBoost
import xgboost as xgb

# Configura√ß√µes de visualiza√ß√£o
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# ===============================================================================
# 1. CARREGAMENTO E EXPLORA√á√ÉO INICIAL DOS DADOS
# ===============================================================================

def load_and_explore_data(file_path):
    """Carrega e faz explora√ß√£o inicial dos dados"""
    
    print("="*60)
    print("üåæ AN√ÅLISE DE PRODU√á√ÉO DE ARROZ")
    print("="*60)
    
    # Carregamento
    try:
        df = pd.read_csv(file_path)
        print(f"‚úÖ Dados carregados com sucesso!")
        print(f"üìä Shape: {df.shape}")
    except Exception as e:
        print(f"‚ùå Erro ao carregar dados: {e}")
        return None
    
    # Informa√ß√µes b√°sicas
    print("\nüìã INFORMA√á√ïES B√ÅSICAS:")
    print("-" * 40)
    print(df.info())
    
    print("\nüìä ESTAT√çSTICAS DESCRITIVAS:")
    print("-" * 40)
    print(df.describe())
    
    print("\nüîç PRIMEIRAS 5 LINHAS:")
    print("-" * 40)
    print(df.head())
    
    print("\n‚ùå VALORES NULOS:")
    print("-" * 40)
    print(df.isnull().sum())
    
    return df

# ===============================================================================
# 2. ENGENHARIA DE FEATURES
# ===============================================================================

def feature_engineering(df):
    """Cria novas features relevantes para agricultura"""
    
    print("\nüîß ENGENHARIA DE FEATURES")
    print("="*40)
    
    df_fe = df.copy()
    
    # 1. Features de Nutrientes
    print("üìä Criando features de nutrientes...")
    df_fe['NPK_Total'] = df_fe['Nitrogen'] + df_fe['POTASH'] + df_fe['PHOSPHATE']
    df_fe['N_P_Ratio'] = df_fe['Nitrogen'] / (df_fe['PHOSPHATE'] + 1)  # +1 para evitar divis√£o por 0
    df_fe['N_K_Ratio'] = df_fe['Nitrogen'] / (df_fe['POTASH'] + 1)
    df_fe['P_K_Ratio'] = df_fe['PHOSPHATE'] / (df_fe['POTASH'] + 1)
    
    # 2. Features H√≠dricas
    print("üíß Criando features h√≠dricas...")
    df_fe['Water_Efficiency'] = df_fe['RICE_PRODUCTION'] / (df_fe['ANNUAL'] + 1)
    df_fe['Rain_Intensity'] = df_fe['avg_rain'] / (df_fe['ANNUAL'] / 365)  # chuva di√°ria m√©dia
    
    # 3. √çndice de Fertilidade
    print("üå± Criando √≠ndice de fertilidade...")
    # Normalizar nutrientes para criar √≠ndice
    scaler_temp = StandardScaler()
    nutrients_normalized = scaler_temp.fit_transform(df_fe[['Nitrogen', 'POTASH', 'PHOSPHATE']])
    df_fe['Fertility_Index'] = np.mean(nutrients_normalized, axis=1)
    
    # 4. Tipo de Solo Dominante
    print("üèûÔ∏è Identificando solo dominante...")
    soil_cols = [col for col in df_fe.columns if col not in ['ANNUAL', 'avg_rain', 'Nitrogen', 
                                                            'POTASH', 'PHOSPHATE', 'RICE_PRODUCTION']]
    
    # Encontrar solo com maior propor√ß√£o
    df_fe['Dominant_Soil'] = df_fe[soil_cols].idxmax(axis=1)
    df_fe['Soil_Diversity'] = (df_fe[soil_cols] > 0).sum(axis=1)  # N√∫mero de tipos de solo presentes
    
    # 5. Intera√ß√µes importantes
    print("üîó Criando intera√ß√µes...")
    df_fe['Nitrogen_x_Rain'] = df_fe['Nitrogen'] * df_fe['avg_rain']
    df_fe['NPK_x_Water'] = df_fe['NPK_Total'] * df_fe['avg_rain']
    
    print(f"‚úÖ Features criadas! Shape anterior: {df.shape}, nova: {df_fe.shape}")
    
    return df_fe

# ===============================================================================
# 3. AN√ÅLISE EXPLORAT√ìRIA DE DADOS (EDA)
# ===============================================================================

def perform_eda(df):
    """An√°lise explorat√≥ria completa"""
    
    print("\nüìä AN√ÅLISE EXPLORAT√ìRIA DE DADOS")
    print("="*50)
    
    # Configurar subplots
    fig = make_subplots(
        rows=3, cols=2,
        subplot_titles=('Distribui√ß√£o da Produ√ß√£o', 'Correla√ß√µes com Produ√ß√£o',
                       'Nutrientes vs Produ√ß√£o', 'Precipita√ß√£o vs Produ√ß√£o',
                       'Distribui√ß√£o de Nutrientes', 'Efici√™ncia H√≠drica'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # 1. Distribui√ß√£o da vari√°vel target
    fig.add_trace(
        go.Histogram(x=df['RICE_PRODUCTION'], name='Produ√ß√£o de Arroz', 
                    marker_color='lightblue', opacity=0.7),
        row=1, col=1
    )
    
    # 2. Correla√ß√µes principais
    correlations = df[['ANNUAL', 'avg_rain', 'Nitrogen', 'POTASH', 'PHOSPHATE', 'RICE_PRODUCTION']].corr()['RICE_PRODUCTION'].drop('RICE_PRODUCTION')
    
    fig.add_trace(
        go.Bar(x=correlations.index, y=correlations.values, 
               name='Correla√ß√£o com Produ√ß√£o',
               marker_color=['red' if x < 0 else 'green' for x in correlations.values]),
        row=1, col=2
    )
    
    # 3. Scatter: Nutrientes vs Produ√ß√£o
    fig.add_trace(
        go.Scatter(x=df['NPK_Total'], y=df['RICE_PRODUCTION'],
                  mode='markers', name='NPK Total vs Produ√ß√£o',
                  marker=dict(size=8, color=df['avg_rain'], 
                            colorscale='Viridis', showscale=True,
                            colorbar=dict(title="Chuva M√©dia"))),
        row=2, col=1
    )
    
    # 4. Scatter: Precipita√ß√£o vs Produ√ß√£o
    fig.add_trace(
        go.Scatter(x=df['ANNUAL'], y=df['RICE_PRODUCTION'],
                  mode='markers', name='Precipita√ß√£o vs Produ√ß√£o',
                  marker=dict(size=8, color='orange')),
        row=2, col=2
    )
    
    # 5. Box plot de nutrientes
    nutrients = ['Nitrogen', 'POTASH', 'PHOSPHATE']
    for i, nutrient in enumerate(nutrients):
        fig.add_trace(
            go.Box(y=df[nutrient], name=nutrient, 
                  marker_color=px.colors.qualitative.Set1[i]),
            row=3, col=1
        )
    
    # 6. Efici√™ncia H√≠drica
    fig.add_trace(
        go.Scatter(x=df['Water_Efficiency'], y=df['RICE_PRODUCTION'],
                  mode='markers', name='Efici√™ncia H√≠drica',
                  marker=dict(size=10, color='purple')),
        row=3, col=2
    )
    
    # Atualizar layout
    fig.update_layout(height=1200, showlegend=True, 
                     title_text="An√°lise Explorat√≥ria - Produ√ß√£o de Arroz")
    fig.show()
    
    # Matriz de Correla√ß√£o
    plt.figure(figsize=(12, 10))
    correlation_matrix = df.select_dtypes(include=[np.number]).corr()
    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdYlBu_r', 
                center=0, square=True, fmt='.2f')
    plt.title('Matriz de Correla√ß√£o', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()
    
    return correlations

# ===============================================================================
# 4. AN√ÅLISE DE OUTLIERS
# ===============================================================================

def detect_outliers(df):
    """Detecta e analisa outliers"""
    
    print("\nüéØ DETEC√á√ÉO DE OUTLIERS")
    print("="*30)
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    outliers_summary = {}
    
    for col in numeric_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
        outliers_summary[col] = len(outliers)
        
        if len(outliers) > 0:
            print(f"‚ö†Ô∏è  {col}: {len(outliers)} outliers detectados")
    
    # Visualizar outliers
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.ravel()
    
    main_cols = ['RICE_PRODUCTION', 'Nitrogen', 'POTASH', 'PHOSPHATE', 'ANNUAL', 'avg_rain']
    
    for i, col in enumerate(main_cols):
        if i < len(axes):
            df.boxplot(column=col, ax=axes[i])
            axes[i].set_title(f'Outliers: {col}')
            axes[i].tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.suptitle('An√°lise de Outliers por Vari√°vel', fontsize=16, y=1.02)
    plt.show()
    
    return outliers_summary

# ===============================================================================
# 5. PREPROCESSAMENTO
# ===============================================================================

def preprocess_data(df):
    """Preprocessa dados para machine learning"""
    
    print("\nüîÑ PREPROCESSAMENTO DOS DADOS")
    print("="*40)
    
    # Separar features num√©ricas
    numeric_features = df.select_dtypes(include=[np.number]).columns.drop('RICE_PRODUCTION')
    target = 'RICE_PRODUCTION'
    
    X = df[numeric_features]
    y = df[target]
    
    print(f"Features selecionadas: {len(numeric_features)}")
    print(f"Samples: {len(X)}")
    
    # Split treino/teste
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=None
    )
    
    # Normaliza√ß√£o
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    X_train_scaled = pd.DataFrame(X_train_scaled, columns=numeric_features, index=X_train.index)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=numeric_features, index=X_test.index)
    
    print("‚úÖ Preprocessamento conclu√≠do!")
    print(f"Treino: {X_train_scaled.shape}, Teste: {X_test_scaled.shape}")
    
    return X_train_scaled, X_test_scaled, y_train, y_test, scaler

# ===============================================================================
# 6. MODELAGEM MACHINE LEARNING
# ===============================================================================

def train_models(X_train, X_test, y_train, y_test):
    """Treina m√∫ltiplos modelos e compara performance"""
    
    print("\nü§ñ TREINAMENTO DE MODELOS")
    print("="*40)
    
    models = {
        'Linear Regression': LinearRegression(),
        'Ridge': Ridge(alpha=1.0),
        'Lasso': Lasso(alpha=1.0),
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
        'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42),
        'SVR': SVR(kernel='rbf', C=100, gamma=0.1)
    }
    
    results = {}
    predictions = {}
    
    for name, model in models.items():
        print(f"üîÑ Treinando {name}...")
        
        # Treinar modelo
        model.fit(X_train, y_train)
        
        # Predi√ß√µes
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        predictions[name] = y_pred_test
        
        # M√©tricas
        train_r2 = r2_score(y_train, y_pred_train)
        test_r2 = r2_score(y_test, y_pred_test)
        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
        test_mae = mean_absolute_error(y_test, y_pred_test)
        
        # Cross-validation
        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')
        
        results[name] = {
            'Train R¬≤': train_r2,
            'Test R¬≤': test_r2,
            'Test RMSE': test_rmse,
            'Test MAE': test_mae,
            'CV R¬≤ Mean': cv_scores.mean(),
            'CV R¬≤ Std': cv_scores.std(),
            'Model': model
        }
        
        print(f"   Test R¬≤: {test_r2:.4f} | RMSE: {test_rmse:.2f} | CV R¬≤: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})")
    
    # Criar DataFrame com resultados
    results_df = pd.DataFrame(results).T
    results_df = results_df.sort_values('Test R¬≤', ascending=False)
    
    print("\nüèÜ RANKING DOS MODELOS:")
    print("-" * 50)
    print(results_df[['Test R¬≤', 'Test RMSE', 'CV R¬≤ Mean']].round(4))
    
    return results, predictions, results_df

# ===============================================================================
# 7. INTERPRETABILIDADE COM SHAP
# ===============================================================================

def interpret_model(best_model, X_train, X_test, feature_names):
    """An√°lise de interpretabilidade usando SHAP"""
    
    print("\nüîç AN√ÅLISE DE INTERPRETABILIDADE")
    print("="*40)
    
    try:
        # Criar explainer SHAP
        if hasattr(best_model, 'predict'):
            explainer = shap.Explainer(best_model, X_train)
            shap_values = explainer(X_test)
        
        # Summary plot
        plt.figure(figsize=(10, 8))
        shap.summary_plot(shap_values, X_test, feature_names=feature_names, show=False)
        plt.title('SHAP Summary Plot - Import√¢ncia das Features')
        plt.tight_layout()
        plt.show()
        
        # Feature importance
        feature_importance = np.abs(shap_values.values).mean(0)
        importance_df = pd.DataFrame({
            'Feature': feature_names,
            'Importance': feature_importance
        }).sort_values('Importance', ascending=False)
        
        # Plotar import√¢ncia
        fig = px.bar(importance_df.head(10), x='Importance', y='Feature', 
                    orientation='h', title='Top 10 Features Mais Importantes')
        fig.show()
        
        print("‚úÖ An√°lise de interpretabilidade conclu√≠da!")
        return importance_df
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro na interpretabilidade: {e}")
        return None

# ===============================================================================
# 8. VISUALIZA√á√ïES DE PERFORMANCE
# ===============================================================================

def plot_model_performance(results, predictions, y_test):
    """Visualiza performance dos modelos"""
    
    print("\nüìà VISUALIZA√á√ïES DE PERFORMANCE")
    print("="*40)
    
    # 1. Compara√ß√£o de m√©tricas
    models_names = list(results.keys())
    r2_scores = [results[model]['Test R¬≤'] for model in models_names]
    rmse_scores = [results[model]['Test RMSE'] for model in models_names]
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('R¬≤ Score Comparison', 'RMSE Comparison', 
                       'Predictions vs Actual', 'Residuals Analysis')
    )
    
    # R¬≤ comparison
    fig.add_trace(
        go.Bar(x=models_names, y=r2_scores, name='R¬≤ Score',
               marker_color='lightblue'),
        row=1, col=1
    )
    
    # RMSE comparison
    fig.add_trace(
        go.Bar(x=models_names, y=rmse_scores, name='RMSE',
               marker_color='lightcoral'),
        row=1, col=2
    )
    
    # Best model predictions vs actual
    best_model_name = max(results.keys(), key=lambda k: results[k]['Test R¬≤'])
    best_predictions = predictions[best_model_name]
    
    fig.add_trace(
        go.Scatter(x=y_test, y=best_predictions, mode='markers',
                  name=f'{best_model_name} Predictions',
                  marker=dict(size=8, color='green')),
        row=2, col=1
    )
    
    # Perfect prediction line
    min_val = min(min(y_test), min(best_predictions))
    max_val = max(max(y_test), max(best_predictions))
    fig.add_trace(
        go.Scatter(x=[min_val, max_val], y=[min_val, max_val],
                  mode='lines', name='Perfect Prediction',
                  line=dict(color='red', dash='dash')),
        row=2, col=1
    )
    
    # Residuals
    residuals = y_test - best_predictions
    fig.add_trace(
        go.Scatter(x=best_predictions, y=residuals, mode='markers',
                  name='Residuals', marker=dict(size=8, color='purple')),
        row=2, col=2
    )
    
    fig.add_trace(
        go.Scatter(x=[min(best_predictions), max(best_predictions)], y=[0, 0],
                  mode='lines', name='Zero Line',
                  line=dict(color='black', dash='dash')),
        row=2, col=2
    )
    
    fig.update_layout(height=800, showlegend=True,
                     title_text=f"An√°lise de Performance - Melhor Modelo: {best_model_name}")
    fig.show()
    
    return best_model_name

# ===============================================================================
# 9. INSIGHTS E RECOMENDA√á√ïES AGRON√îMICAS
# ===============================================================================

def generate_agricultural_insights(df, importance_df, correlations):
    """Gera insights agron√¥micos baseados na an√°lise"""
    
    print("\nüåæ INSIGHTS AGRON√îMICOS")
    print("="*40)
    
    insights = []
    
    # 1. An√°lise de Nutrientes
    nitrogen_corr = correlations.get('Nitrogen', 0)
    potash_corr = correlations.get('POTASH', 0)
    phosphate_corr = correlations.get('PHOSPHATE', 0)
    
    if nitrogen_corr > 0.5:
        insights.append("üí° NITROG√äNIO: Forte correla√ß√£o positiva com produ√ß√£o. Aumentar aplica√ß√£o de N pode incrementar rendimento.")
    elif nitrogen_corr < -0.3:
        insights.append("‚ö†Ô∏è  NITROG√äNIO: Correla√ß√£o negativa detectada. Poss√≠vel excesso causando perdas.")
    
    # 2. An√°lise H√≠drica
    rain_corr = correlations.get('avg_rain', 0)
    annual_corr = correlations.get('ANNUAL', 0)
    
    if rain_corr > 0.3:
        insights.append("üíß IRRIGA√á√ÉO: Chuva m√©dia mostra correla√ß√£o positiva. Manejo h√≠drico √© crucial.")
    
    # 3. An√°lise de Solo
    soil_diversity_mean = df['Soil_Diversity'].mean()
    insights.append(f"üèûÔ∏è  SOLO: Diversidade m√©dia de tipos de solo: {soil_diversity_mean:.1f}")
    
    # 4. Efici√™ncia
    water_eff_mean = df['Water_Efficiency'].mean()
    insights.append(f"‚ö° EFICI√äNCIA H√çDRICA: M√©dia de {water_eff_mean:.2f} kg/mm de chuva")
    
    # 5. Recomenda√ß√µes baseadas em ranges √≥timos
    high_producers = df[df['RICE_PRODUCTION'] > df['RICE_PRODUCTION'].quantile(0.75)]
    
    optimal_nitrogen = high_producers['Nitrogen'].mean()
    optimal_potash = high_producers['POTASH'].mean()
    optimal_phosphate = high_producers['PHOSPHATE'].mean()
    optimal_rain = high_producers['avg_rain'].mean()
    
    insights.extend([
        f"üéØ F√ìRMULA √ìTIMA (baseada nos 25% mais produtivos):",
        f"   ‚Ä¢ Nitrog√™nio: {optimal_nitrogen:,.0f} kg/ha",
        f"   ‚Ä¢ Pot√°ssio: {optimal_potash:,.0f} kg/ha", 
        f"   ‚Ä¢ F√≥sforo: {optimal_phosphate:,.0f} kg/ha",
        f"   ‚Ä¢ Chuva ideal: {optimal_rain:.1f} mm/m√™s"
    ])
    
    # 6. Alertas de Sustentabilidade
    max_nitrogen = df['Nitrogen'].max()
    if max_nitrogen > 100000:  # Threshold alto
        insights.append("‚ö†Ô∏è  SUSTENTABILIDADE: N√≠veis muito altos de N detectados. Revisar para evitar lixivia√ß√£o.")
    
    print("\n".join(insights))
    
    return insights, {
        'optimal_nitrogen': optimal_nitrogen,
        'optimal_potash': optimal_potash,
        'optimal_phosphate': optimal_phosphate,
        'optimal_rain': optimal_rain
    }

# ===============================================================================
# 10. FUN√á√ÉO PRINCIPAL
# ===============================================================================

def main():
    """Fun√ß√£o principal que executa toda a an√°lise"""
    
    print("üöÄ INICIANDO AN√ÅLISE COMPLETA DE PRODU√á√ÉO DE ARROZ")
    print("="*60)
    
    # 1. Carregar dados
    df = load_and_explore_data('X1.csv')
    if df is None:
        return
    
    # 2. Feature Engineering
    df_enhanced = feature_engineering(df)
    
    # 3. EDA
    correlations = perform_eda(df_enhanced)
    
    # 4. Detec√ß√£o de outliers
    outliers = detect_outliers(df_enhanced)
    
    # 5. Preprocessamento
    X_train, X_test, y_train, y_test, scaler = preprocess_data(df_enhanced)
    
    # 6. Modelagem
    results, predictions, results_df = train_models(X_train, X_test, y_train, y_test)
    
    # 7. Melhor modelo
    best_model_name = max(results.keys(), key=lambda k: results[k]['Test R¬≤'])
    best_model = results[best_model_name]['Model']
    
    print(f"\nüèÜ MELHOR MODELO: {best_model_name}")
    print(f"   R¬≤ Score: {results[best_model_name]['Test R¬≤']:.4f}")
    print(f"   RMSE: {results[best_model_name]['Test RMSE']:.2f}")
    
    # 8. Interpretabilidade
    importance_df = interpret_model(best_model, X_train, X_test, X_train.columns)
    
    # 9. Visualiza√ß√µes de performance
    plot_model_performance(results, predictions, y_test)
    
    # 10. Insights agron√¥micos
    insights, optimal_params = generate_agricultural_insights(df_enhanced, importance_df, correlations)
    
    # 11. Resumo executivo
    print("\n" + "="*60)
    print("üìä RESUMO EXECUTIVO")
    print("="*60)
    print(f"üéØ Melhor Modelo: {best_model_name}")
    print(f"üìà Acur√°cia (R¬≤): {results[best_model_name]['Test R¬≤']:.1%}")
    print(f"üìâ Erro M√©dio: ¬±{results[best_model_name]['Test RMSE']:.0f} kg/ha")
    print(f"üåæ Dataset: {len(df)} observa√ß√µes, {len(X_train.columns)} features")
    
    if importance_df is not None:
        top_feature = importance_df.iloc[0]['Feature']
        print(f"üîë Feature mais importante: {top_feature}")
    
    print(f"üíß Efici√™ncia h√≠drica m√©dia: {df_enhanced['Water_Efficiency'].mean():.2f} kg/mm")
    print("‚úÖ An√°lise completa finalizada!")
    
    return {
        'df': df_enhanced,
        'results': results,
        'best_model': best_model,
        'best_model_name': best_model_name,
        'importance': importance_df,
        'insights': insights,
        'optimal_params': optimal_params
    }

# ===============================================================================
# EXECUTAR AN√ÅLISE
# ===============================================================================

if __name__ == "__main__":
    # Executar an√°lise completa
    analysis_results = main()
    
    # Salvar resultados
    print("\nüíæ Salvando resultados...")
    
    # Salvar modelo (exemplo com pickle)
    # import pickle
    # with open('best_rice_model.pkl', 'wb') as f:
    #     pickle.dump(analysis_results['best_model'], f)
    
    # Salvar insights
    # with open('agricultural_insights.txt', 'w') as f:
    #     f.write('\n'.join(analysis_results['insights']))
    
    print("üéâ Projeto conclu√≠do com sucesso!")
    print("üìÅ Arquivos prontos para portf√≥lio!")